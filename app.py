import streamlit as st
import pandas as pd
import numpy as np
import requests
import pickle
import io
import os
from datetime import date, timedelta, datetime
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
from google.oauth2 import service_account
from googleapiclient.discovery import build
from googleapiclient.http import MediaIoBaseDownload, MediaFileUpload
import matplotlib.pyplot as plt

@st.cache_resource
def create_drive_service():
    credentials = service_account.Credentials.from_service_account_info({
        "type": "service_account",
        "project_id": st.secrets["GDRIVE_PROJECT_ID"],
        "private_key_id": "",
        "private_key": st.secrets["GDRIVE_PRIVATE_KEY"].replace("\\n", "\n"),
        "client_email": st.secrets["GDRIVE_CLIENT_EMAIL"],
        "client_id": st.secrets["GDRIVE_CLIENT_ID"],
        "auth_uri": "https://accounts.google.com/o/oauth2/auth",
        "token_uri": "https://oauth2.googleapis.com/token",
        "auth_provider_x509_cert_url": "https://www.googleapis.com/oauth2/v1/certs",
        "client_x509_cert_url": f"https://www.googleapis.com/robot/v1/metadata/x509/{st.secrets['GDRIVE_CLIENT_EMAIL'].replace('@', '%40')}"
    })
    return build('drive', 'v3', credentials=credentials)

def find_drive_file(service, filename):
    query = f"name='{filename}' and trashed=false"
    results = service.files().list(q=query, fields="files(id, name)").execute()
    files = results.get("files", [])
    return files[0]["id"] if files else None

def download_model(service, filename):
    file_id = find_drive_file(service, filename)
    if not file_id:
        return None
    request = service.files().get_media(fileId=file_id)
    fh = io.BytesIO()
    downloader = MediaIoBaseDownload(fh, request)
    done = False
    while not done:
        _, done = downloader.next_chunk()
    fh.seek(0)
    return pickle.load(fh)

def upload_model(service, filename, model):
    with open(filename, "wb") as f:
        pickle.dump(model, f)
    file_metadata = {"name": filename}
    media = MediaFileUpload(filename, mimetype="application/octet-stream")
    service.files().create(body=file_metadata, media_body=media, fields="id").execute()
    os.remove(filename)

# ================== App ====================
lang = st.sidebar.selectbox("Language / Ø§Ù„Ù„ØºØ©", ["English", "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©"])
is_ar = lang == "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©"
st.title("AI-Based Weather Forecast" if not is_ar else "ØªÙˆÙ‚Ø¹ Ø§Ù„Ø·Ù‚Ø³ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ")

city_coords = {
    "USA": {"New York": (40.71, -74.01), "Los Angeles": (34.05, -118.24)},
    "Saudi Arabia": {"Riyadh": (24.7136, 46.6753), "Jeddah": (21.4858, 39.1925)},
    "Germany": {"Berlin": (52.52, 13.4050), "Munich": (48.1351, 11.5820)}
}

st.sidebar.markdown("### ğŸŒ " + ("Ø§Ø®ØªØ± Ø§Ù„Ø¯ÙˆÙ„Ø© ÙˆØ§Ù„Ù…Ø¯ÙŠÙ†Ø©" if is_ar else "Select Country and City"))
country = st.sidebar.selectbox("Country / Ø§Ù„Ø¯ÙˆÙ„Ø©", list(city_coords.keys()))
city = st.sidebar.selectbox("City / Ø§Ù„Ù…Ø¯ÙŠÙ†Ø©", list(city_coords[country].keys()))
lat, lon = city_coords[country][city]

st.sidebar.markdown("### ğŸ”§ " + ("Ù…Ø§Ø°Ø§ ØªØ±ÙŠØ¯ Ø£Ù† ÙŠØªÙ… Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¨Ù‡ØŸ" if is_ar else "Select what to predict"))
all_vars = {
    "ğŸŒ¡ï¸ " + ("Temperature" if not is_ar else "Ø¯Ø±Ø¬Ø© Ø§Ù„Ø­Ø±Ø§Ø±Ø©"): "temperature",
    "ğŸ’§ " + ("Humidity" if not is_ar else "Ø§Ù„Ø±Ø·ÙˆØ¨Ø©"): "humidity",
    "ğŸŒ¬ï¸ " + ("Wind Speed" if not is_ar else "Ø³Ø±Ø¹Ø© Ø§Ù„Ø±ÙŠØ§Ø­"): "wind_speed"
}
selected_display = st.sidebar.multiselect("", list(all_vars.keys()), default=list(all_vars.keys()))
selected_vars = [all_vars[d] for d in selected_display]

st.sidebar.markdown("### ğŸ”¢ " + ("Select units" if not is_ar else "Ø§Ø®ØªØ± ÙˆØ­Ø¯Ø§Øª Ø§Ù„Ù‚ÙŠØ§Ø³"))
unit_temp = st.sidebar.radio("Temperature", ["C", "F"], index=0)
unit_wind = st.sidebar.radio("Wind Speed", ["km/h", "m/s"], index=0)

if st.sidebar.button("Start Prediction" if not is_ar else "Ø§Ø¨Ø¯Ø£ Ø§Ù„ØªÙ†Ø¨Ø¤"):
    start_date = (date.today() - timedelta(days=730)).isoformat()
    end_date = date.today().isoformat()
    api_url = (
        f"https://archive-api.open-meteo.com/v1/archive?latitude={lat}&longitude={lon}"
        f"&start_date={start_date}&end_date={end_date}"
        f"&hourly=temperature_2m,relative_humidity_2m,windspeed_10m&timezone=auto"
    )

    response = requests.get(api_url)
    response.raise_for_status()
    data = response.json()
    df = pd.DataFrame({
        "datetime": pd.to_datetime(data["hourly"]["time"]),
        "temperature": data["hourly"]["temperature_2m"],
        "humidity": data["hourly"]["relative_humidity_2m"],
        "wind_speed": data["hourly"]["windspeed_10m"]
    })

    def fill_with_avg_of_neighbors(series):
        series = series.copy()
        for i in range(1, len(series) - 1):
            if pd.isna(series[i]) and not pd.isna(series[i - 1]) and not pd.isna(series[i + 1]):
                series[i] = (series[i - 1] + series[i + 1]) / 2
        return series

    for col in df.columns[1:]:
        df[col] = fill_with_avg_of_neighbors(df[col])
        df[col] = df[col].fillna(method="ffill").fillna(method="bfill")

    look_back = 72
    hours_ahead = 24
    forecast_results = {}
    service = create_drive_service()

    for var in selected_vars:
        X, y = [], []
        data_arr = df[[var]].values
        for i in range(len(data_arr) - look_back):
            X.append(data_arr[i:i+look_back].flatten())
            y.append(data_arr[i+look_back][0])
        X, y = np.array(X), np.array(y)

        X_train, _, y_train, _ = train_test_split(X, y, shuffle=False, test_size=0.2)
        model_filename = f"{country}_{city}_{var}.pkl"
        model = download_model(service, model_filename)

        if not model:
            model = LinearRegression()
            model.fit(X_train, y_train)
            upload_model(service, model_filename, model)

        current_sequence = df[[var]].values[-look_back:].flatten().reshape(1, -1)
        hourly_preds = []
        for _ in range(hours_ahead):
            pred = model.predict(current_sequence)[0]
            hourly_preds.append(pred)
            current_sequence = np.append(current_sequence[:, 1:], [[pred]], axis=1)

        forecast_results[var] = hourly_preds

    start_time = datetime.combine(date.today() + timedelta(days=1), datetime.min.time())
    hourly_times = [start_time + timedelta(hours=i) for i in range(hours_ahead)]
    df_forecast = pd.DataFrame({"Time": hourly_times})

    if "temperature" in forecast_results:
        temp = forecast_results["temperature"]
        if unit_temp == "F":
            temp = [(t * 9/5) + 32 for t in temp]
        df_forecast[f"Temperature ({unit_temp})"] = temp

    if "humidity" in forecast_results:
        df_forecast["Humidity (%)"] = forecast_results["humidity"]

    if "wind_speed" in forecast_results:
        wind = forecast_results["wind_speed"]
        if unit_wind == "m/s":
            wind = [w / 3.6 for w in wind]
        df_forecast[f"Wind Speed ({unit_wind})"] = wind

    def plot_line_chart(df, column, title):
        fig, ax = plt.subplots()
        ax.plot(df["Time"], df[column], marker='o')
        ax.set_title(title)
        ax.set_xlabel("Time")
        ax.set_ylabel(column)
        ax.grid(True)
        plt.xticks(rotation=45)
        st.pyplot(fig)

    st.subheader("Hourly Weather Forecast for Tomorrow" if not is_ar else "ØªÙˆÙ‚Ø¹Ø§Øª Ø§Ù„Ø·Ù‚Ø³ Ù„ÙƒÙ„ Ø³Ø§Ø¹Ø© ØºØ¯Ù‹Ø§")
    st.markdown(f"ğŸ“ {city}, {country}")
    st.markdown(f"ğŸ“… {date.today() + timedelta(days=1)}")

    for col in df_forecast.columns:
        if col != "Time":
            label = col.split(" (")[0]
            emoji = "ğŸŒ¡ï¸" if "Temp" in col else "ğŸ’§" if "Humidity" in col else "ğŸŒ¬ï¸"
            title = emoji + " " + (f"ØªØºÙŠØ± {label}" if is_ar else f"{label} Throughout the Day")
            plot_line_chart(df_forecast, col, title)

    st.dataframe(df_forecast.style.format(precision=1))
